{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras.callbacks as cb\n",
    "import time\n",
    "import numpy as np\n",
    "from data import get_datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from functools import partial\n",
    "from data import get_datasets\n",
    "from experiment import create_model, evaluate\n",
    "from sentiment import sentiment\n",
    "import model_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_dataset, test_dataset), info = get_datasets() #batch_size=1)\n",
    "encoder = info.features['text'].encoder\n",
    "vocab_size=info.features['text'].encoder.vocab_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previously trained model.\n"
     ]
    }
   ],
   "source": [
    "transformer, _optimizer, _checkpoint, _manager = create_model(models_dir=\"models/pos_enc_True\", load_checkpoint=True, \n",
    "                           vocab_size=vocab_size, use_positional_encoding=True, run_eagerly=True)\n",
    "\n",
    "# adv = model_adv.create_model(models_dir=\"adv\", load_checkpoint=False, run_eagerly=True, d_model=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82691425\n"
     ]
    }
   ],
   "source": [
    "# Initial accuracy\n",
    "metrics = evaluate(transformer, test_dataset)\n",
    "print(metrics.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "D_MODEL = 128\n",
    "\n",
    "adv, optimizer = model_adv.create_model(models_dir=\"adv\", load_checkpoint=False, \n",
    "                                            run_eagerly=True, d_model=D_MODEL)\n",
    "    \n",
    "def find_adv_k(x, y, transformer):\n",
    "    \"\"\"\n",
    "    x - (batch, text)\n",
    "    y - (batch, label)\n",
    "    \n",
    "    Passes x through transformer and receives y_logits, w, k.\n",
    "    Creates an adversarial model - adv.\n",
    "    Pass k through adv model and receives adv_k.\n",
    "    Computes loss by passing (x, custom_k=adv_k) through transformer:\n",
    "        Receives adv_y_logits, adv_w, adv_k (same k)\n",
    "        loss_t = tf.keras.losses.binary_crossentropy(y_true=y, y_pred=adv_y_logits, from_logits=True)\n",
    "        loss_k = - |k - adv_k|\n",
    "        loss = loss_t + loss_k\n",
    "    \n",
    "    Returns: \n",
    "        k - original k\n",
    "        w - original attention weights\n",
    "        adv_k - adversarial k\n",
    "        adv_w - adversarial attention weights w\n",
    "        loss_k - the one that is maximized\n",
    "        loss_t - transformer loss (the one that is minimized)\n",
    "        loss - adversarial loss, e.g.  loss = loss_t = loss_k\n",
    "    \"\"\"\n",
    "    best_loss_t = None\n",
    "    best_adv_k = None\n",
    "    \n",
    "\n",
    "    y_logits, w, k = transformer(x, training=False)\n",
    "    print(f'Returned k: {tf.shape(k)}')\n",
    "    y_logits2, _, _ = transformer(x, training=False, custom_k=k)\n",
    "    \n",
    "    \n",
    "    loss_t = tf.keras.losses.binary_crossentropy(y_true=y, y_pred=y_logits, from_logits=True)\n",
    "    best_loss_t = loss_t\n",
    "    original_loss_t = loss_t\n",
    "    original_k = k\n",
    "    \n",
    "    print(f'[{0}] Loss_t = {loss_t:<20.10}')\n",
    "    loss_t = tf.keras.losses.binary_crossentropy(y_true=y, y_pred=y_logits2, from_logits=True)\n",
    "    print(f'[{0}] Loss_t (custom k) = {loss_t:<20.10}')\n",
    "    \n",
    "    alpha = 0.5\n",
    "    \n",
    "    \n",
    "    for epoch in range(1, EPOCHS+1):        \n",
    "        with tf.GradientTape() as tape:\n",
    "            adv_k = adv(k, training=True)\n",
    "            if best_adv_k is None:\n",
    "                best_adv_k = adv_k\n",
    "            \n",
    "            adv_y_logits, adv_w, adv_k2  = transformer(x, custom_k=adv_k, training=False)\n",
    "            cond = tf.reduce_all(tf.equal(adv_k, adv_k2)).numpy()\n",
    "            bs = tf.shape(k)[0]\n",
    "            assert cond == True\n",
    "            loss_t = tf.keras.losses.binary_crossentropy(y_true=y, y_pred=adv_y_logits, from_logits=True)\n",
    "            summed = tf.math.reduce_sum(tf.math.pow(tf.reshape(k, [bs, -1]) - tf.reshape(adv_k, [bs, -1]), 2), axis=1)\n",
    "            \n",
    "            loss_k = - tf.math.log(tf.math.reduce_mean(summed))\n",
    "            \n",
    "            loss = alpha*loss_t + (1 - alpha)*loss_k\n",
    "            \n",
    "            if loss_t < best_loss_t:\n",
    "                best_loss_t = loss_t\n",
    "                best_adv_k  = adv_k\n",
    "            \n",
    "        \n",
    "        print(f'[{epoch:<2}] Loss_t = {loss_t:<20.10}  Loss_k = {loss_k:<20.10}   Loss = {loss:<20.10}')\n",
    "\n",
    "        grads = tape.gradient(loss, adv.trainable_weights)                \n",
    "        optimizer.apply_gradients(zip(grads, adv.trainable_weights))\n",
    "  \n",
    "    return original_loss_t, original_k, best_loss_t, best_adv_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned k: [ 64   4 199 128]\n",
      "[0] Loss_t = 0.1198091134        \n",
      "[0] Loss_t (custom k) = 0.1198091134        \n",
      "[1 ] Loss_t = 0.2460487336          Loss_k = -17.12693787           Loss = -8.440444946        \n",
      "[2 ] Loss_t = 0.1655866802          Loss_k = -17.18998146           Loss = -8.512197495        \n",
      "[3 ] Loss_t = 0.1474911571          Loss_k = -17.25179863           Loss = -8.552153587        \n",
      "[4 ] Loss_t = 0.145966202           Loss_k = -17.31235313           Loss = -8.583193779        \n",
      "[5 ] Loss_t = 0.1431607604          Loss_k = -17.37161255           Loss = -8.614226341        \n",
      "[6 ] Loss_t = 0.138781175           Loss_k = -17.42959595           Loss = -8.645407677        \n",
      "[7 ] Loss_t = 0.1318671852          Loss_k = -17.48634338           Loss = -8.677238464        \n",
      "[8 ] Loss_t = 0.123671256           Loss_k = -17.54191589           Loss = -8.709122658        \n",
      "[9 ] Loss_t = 0.117032364           Loss_k = -17.59639549           Loss = -8.739681244        \n",
      "[10] Loss_t = 0.1128930598          Loss_k = -17.64984131           Loss = -8.768474579        \n",
      "[11] Loss_t = 0.1101054922          Loss_k = -17.70228767           Loss = -8.79609108         \n",
      "[12] Loss_t = 0.1068932414          Loss_k = -17.75375938           Loss = -8.823432922        \n",
      "[13] Loss_t = 0.1022463739          Loss_k = -17.80428886           Loss = -8.851020813        \n",
      "[14] Loss_t = 0.09639842063         Loss_k = -17.85392189           Loss = -8.878761292        \n",
      "[15] Loss_t = 0.09030406177         Loss_k = -17.9027195            Loss = -8.906208038        \n",
      "[16] Loss_t = 0.08480469882         Loss_k = -17.95074272           Loss = -8.932969093        \n",
      "[17] Loss_t = 0.08005286753         Loss_k = -17.99803925           Loss = -8.958992958        \n",
      "[18] Loss_t = 0.07590677589         Loss_k = -18.04465103           Loss = -8.984372139        \n",
      "[19] Loss_t = 0.07212951779         Loss_k = -18.09060669           Loss = -9.009238243        \n",
      "[20] Loss_t = 0.0685736686          Loss_k = -18.13591957           Loss = -9.033673286        \n",
      "[21] Loss_t = 0.06515833735         Loss_k = -18.18060303           Loss = -9.057722092        \n",
      "[22] Loss_t = 0.0617932044          Loss_k = -18.22465515           Loss = -9.081431389        \n",
      "[23] Loss_t = 0.05842176825         Loss_k = -18.26808739           Loss = -9.104832649        \n",
      "[24] Loss_t = 0.05500134453         Loss_k = -18.31091309           Loss = -9.127955437        \n",
      "[25] Loss_t = 0.05160487816         Loss_k = -18.35315514           Loss = -9.150774956        \n",
      "[26] Loss_t = 0.04831659049         Loss_k = -18.39483833           Loss = -9.173260689        \n",
      "[27] Loss_t = 0.0452648215          Loss_k = -18.43598175           Loss = -9.195358276        \n",
      "[28] Loss_t = 0.042510923           Loss_k = -18.47660828           Loss = -9.217048645        \n",
      "[29] Loss_t = 0.04004569352         Loss_k = -18.51673508           Loss = -9.238345146        \n",
      "[30] Loss_t = 0.03783321381         Loss_k = -18.55637741           Loss = -9.259271622        \n",
      "[31] Loss_t = 0.03583969176         Loss_k = -18.59554291           Loss = -9.279851913        \n",
      "[32] Loss_t = 0.03406257555         Loss_k = -18.63424492           Loss = -9.30009079         \n",
      "[33] Loss_t = 0.03237984329         Loss_k = -18.67249107           Loss = -9.320055962        \n",
      "[34] Loss_t = 0.03076694161         Loss_k = -18.71029282           Loss = -9.339762688        \n",
      "[35] Loss_t = 0.0292024482          Loss_k = -18.74765968           Loss = -9.359229088        \n",
      "[36] Loss_t = 0.02770909294         Loss_k = -18.78459358           Loss = -9.378441811        \n",
      "[37] Loss_t = 0.02631118707         Loss_k = -18.82110023           Loss = -9.39739418         \n",
      "[38] Loss_t = 0.02503544837         Loss_k = -18.85718918           Loss = -9.41607666         \n",
      "[39] Loss_t = 0.02389151789         Loss_k = -18.89286804           Loss = -9.434488297        \n",
      "[40] Loss_t = 0.02288136631         Loss_k = -18.92814064           Loss = -9.452630043        \n",
      "[41] Loss_t = 0.02197827771         Loss_k = -18.96302032           Loss = -9.470520973        \n",
      "[42] Loss_t = 0.02113934234         Loss_k = -18.99751091           Loss = -9.488185883        \n",
      "[43] Loss_t = 0.02034023404         Loss_k = -19.03162193           Loss = -9.505640984        \n",
      "[44] Loss_t = 0.01955813169         Loss_k = -19.06535912           Loss = -9.522900581        \n",
      "[45] Loss_t = 0.01878781244         Loss_k = -19.09872818           Loss = -9.539970398        \n",
      "[46] Loss_t = 0.0180346258          Loss_k = -19.13174057           Loss = -9.556853294        \n",
      "[47] Loss_t = 0.01730719209         Loss_k = -19.1644001            Loss = -9.57354641         \n",
      "[48] Loss_t = 0.01661407575         Loss_k = -19.19672203           Loss = -9.590053558        \n",
      "[49] Loss_t = 0.01596380956         Loss_k = -19.22871208           Loss = -9.606373787        \n",
      "[50] Loss_t = 0.01535868458         Loss_k = -19.2603817            Loss = -9.622511864        \n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_dataset))\n",
    "#     for batch, (x, y) in enumerate(train_dataset):\n",
    "loss_t, k, best_loss_t, best_adv_k = find_adv_k(x, y, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79986244\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate(transformer, test_dataset, adv_model=adv)\n",
    "print(metrics.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214.1467\n",
      "79561.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.norm(k).numpy())\n",
    "print(tf.norm(best_adv_k).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loss_t: 0.0007400644826702774\n",
      "Best loss_t:     0.00014332833234220743\n"
     ]
    }
   ],
   "source": [
    "print(f'Original loss_t: {loss_t}')\n",
    "print(f'Best loss_t:     {best_loss_t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.0622562  -0.23984744  1.0748044   1.3748744 ]\n",
      " [-0.69511235  0.541495   -0.26275066  0.00983193]\n",
      " [ 0.587861    0.8562857   0.37515846  0.7165856 ]\n",
      " [-0.8721777  -0.08632609 -0.13359296 -0.27416104]\n",
      " [-0.9817763  -0.07322308 -0.07859396  1.1635443 ]\n",
      " [-0.5991031  -0.3586921  -0.63432235 -1.2879654 ]\n",
      " [-1.3708589   0.6427558   0.01798093 -0.36737213]\n",
      " [ 2.1075368   0.32159662  0.22088861  0.41846114]\n",
      " [ 0.18461812 -0.52916014  1.0895694  -1.4266332 ]\n",
      " [-0.21394011 -0.13209644 -0.45749953  0.2583496 ]\n",
      " [ 0.8876147   0.55790997  0.8856335   0.17673488]\n",
      " [ 1.8994558   0.9954314   1.8560383   1.3102771 ]\n",
      " [-0.1030802   0.2939429   1.0747086   0.5858982 ]\n",
      " [ 1.9763365  -0.88368344  2.5498774  -0.2831556 ]\n",
      " [ 1.8231454   0.20237808 -0.8465917   0.2549476 ]\n",
      " [-1.0648656  -1.008372    1.7104899   0.34775013]\n",
      " [-0.35755393 -1.0473596  -0.05636305  1.8079398 ]\n",
      " [-0.05273503 -0.01887925 -1.3248074  -1.0591247 ]\n",
      " [-0.7161503   0.5835323   2.18067     0.10653253]\n",
      " [ 1.4768964  -0.48128784 -0.34213793  0.8836418 ]\n",
      " [ 0.12349128  0.25783983 -0.05816101  1.3702736 ]\n",
      " [-0.5774419   1.0708901  -0.41971874  0.7125504 ]\n",
      " [ 2.4242928  -1.5987276  -0.06979925  0.5040399 ]\n",
      " [ 1.0370625  -1.3000015  -1.7664553  -0.11823926]\n",
      " [-0.6102123   1.2571919   0.26929778 -0.07118638]\n",
      " [ 0.8947406  -2.9637318  -2.064201    0.40053374]\n",
      " [ 0.93117255  1.0972146   1.9912081   1.0783393 ]\n",
      " [-0.8630539  -0.18883061  1.4836739   2.5626621 ]\n",
      " [-0.4145677  -0.8505255   1.0938935   2.5544379 ]\n",
      " [-1.1460482  -0.22750667 -0.3987229  -0.6055988 ]\n",
      " [-0.9688484   0.6397894  -0.53200626 -0.27800724]\n",
      " [-1.3501431  -1.1718494  -0.87898654 -1.0261877 ]], shape=(32, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-12.93582    -12.70495     20.852724   -19.397846  ]\n",
      " [-20.314058    20.837696    10.435119   -15.958553  ]\n",
      " [ 14.89877     18.498215    -1.6283331   10.076402  ]\n",
      " [  7.7138505  -15.910409    -6.8799844   16.915518  ]\n",
      " [-16.06042     15.743664   -14.445805    22.352257  ]\n",
      " [ 17.863539   -16.437601   -11.805798   -18.508955  ]\n",
      " [ 17.678596   -16.576855    16.94513     14.728381  ]\n",
      " [-16.812471    15.394816     7.1227574   14.080618  ]\n",
      " [ 16.575653   -15.83942     17.832705    18.440596  ]\n",
      " [  2.6151643   16.627499    15.793617    17.297815  ]\n",
      " [ 15.648141    -1.0274997  -14.406075    19.181173  ]\n",
      " [ 16.137878   -15.308272   -18.015413   -17.080032  ]\n",
      " [ 12.215047    10.306358    13.185185    19.557194  ]\n",
      " [ 15.798789    14.284671     3.5033286  -18.033628  ]\n",
      " [ 16.724266     9.923336   -14.1956215  -20.477636  ]\n",
      " [-16.572039    16.621933     3.566389   -20.107922  ]\n",
      " [-15.083112    15.141306    22.196972   -14.898009  ]\n",
      " [-11.771129    18.128271    18.946093   -20.260893  ]\n",
      " [-12.555454   -16.379166   -13.583757   -18.01645   ]\n",
      " [ 15.232893    12.777744    18.470093     3.014486  ]\n",
      " [-18.668306   -17.8522      17.915007   -15.271763  ]\n",
      " [  0.58551395  17.355608    13.577816    16.882149  ]\n",
      " [ 15.623823    18.00434    -17.787558   -17.20001   ]\n",
      " [-14.584127   -14.513808    15.802755    12.319385  ]\n",
      " [-14.659846   -20.198904   -11.269498   -16.149921  ]\n",
      " [ 17.24548     16.343443    17.130041   -13.393272  ]\n",
      " [ 19.48806    -20.109772    16.004913   -16.41536   ]\n",
      " [ 15.028473    18.316141    12.326775   -14.930901  ]\n",
      " [ 15.121092    17.136726   -17.698845   -19.836197  ]\n",
      " [ 13.657486    15.526376   -13.523767   -16.658924  ]\n",
      " [  7.197608    14.966182    17.973124    20.627394  ]\n",
      " [ 11.812029   -12.836978   -18.143406   -16.200367  ]], shape=(32, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(k[0][0][0],(-1, 4)))\n",
    "print(tf.reshape(best_adv_k[0][0][0], (-1, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('adv_results/x', x.numpy())\n",
    "np.save('adv_results/y', y.numpy())\n",
    "np.save('adv_results/best_adv_k', best_adv_k.numpy())\n",
    "np.save('adv_results/k', k.numpy())\n",
    "np.save('adv_results/loss_t', loss_t.numpy())\n",
    "np.save('adv_results/best_loss_t', best_loss_t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024033187\n",
      "0.01337338\n"
     ]
    }
   ],
   "source": [
    "# Load the best values\n",
    "np.load('adv_results/x.npy')\n",
    "np.load('adv_results/y.npy')\n",
    "np.load('adv_results/best_adv_k.npy')\n",
    "np.load('adv_results/k.npy')\n",
    "print(np.load('adv_results/loss_t.npy'))\n",
    "print(np.load('adv_results/best_loss_t.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
