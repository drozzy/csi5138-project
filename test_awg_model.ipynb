{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_awg import AdversarialWeightGenenerator, create_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is: (2, 100, 100)\n",
      "Output features: 100\n"
     ]
    }
   ],
   "source": [
    "#(batch, num_layers, seq_len, seq_len)\n",
    "num_layers = 2\n",
    "seq_len = 100\n",
    "model, optimizer = create_model(\"test_model\", load_checkpoint=False, num_layers=num_layers, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([55, 2, 100, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal((55, num_layers, seq_len, seq_len))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 2, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 51556\n",
      "Trainable params: 51556\n",
      "Non-trainable params: 0\n"
     ]
    }
   ],
   "source": [
    "trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_count = int(np.sum([K.count_params(w) for w in model.non_trainable_weights]))\n",
    "\n",
    "print(f'Total params: {trainable_count + non_trainable_count}')\n",
    "print(f'Trainable params: {trainable_count}')\n",
    "print(f'Non-trainable params: {non_trainable_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(N=100):\n",
    "    x =  tf.nn.softmax(tf.random.uniform((N, num_layers, seq_len, seq_len)))\n",
    "    y = tf.nn.softmax(tf.random.uniform((N, num_layers, seq_len, seq_len)))\n",
    "#     y = tf.nn.softmax(-2.0*x**3 + 5.0*x**2 -2.0*x + 1.0)\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_dataset()\n",
    "\n",
    "x, y = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2, 100, 100)\n",
      "(100, 2, 100, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=109, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "tf.reduce_sum(y[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, xt, yt):    \n",
    "    \n",
    "    # Eval\n",
    "    ypred = model(xt, training=False)\n",
    "    loss = loss_obj(yt, ypred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is: (2, 100, 100)\n",
      "Output features: 100\n",
      "  1. Out: 4.0291168e-02  In: 4.0298093e-02  \n",
      "100. Out: 4.0260758e-02  In: 4.0248532e-02  \n",
      "200. Out: 4.0262524e-02  In: 4.0224187e-02  \n",
      "300. Out: 4.0268406e-02  In: 4.0193390e-02  \n",
      "400. Out: 4.0282562e-02  In: 4.0156554e-02  \n",
      "500. Out: 4.0309303e-02  In: 4.0119518e-02  \n",
      "600. Out: 4.0345937e-02  In: 4.0090874e-02  \n",
      "700. Out: 4.0382288e-02  In: 4.0073249e-02  \n",
      "800. Out: 4.0410798e-02  In: 4.0063918e-02  \n",
      "900. Out: 4.0430028e-02  In: 4.0058877e-02  \n",
      "1000. Out: 4.0442467e-02  In: 4.0056389e-02  \n",
      "1100. Out: 4.0450189e-02  In: 4.0055007e-02  \n",
      "1200. Out: 4.0454999e-02  In: 4.0054280e-02  \n",
      "1300. Out: 4.0458038e-02  In: 4.0053908e-02  \n",
      "1400. Out: 4.0459964e-02  In: 4.0053636e-02  \n",
      "1500. Out: 4.0461235e-02  In: 4.0053505e-02  \n",
      "1600. Out: 4.0462155e-02  In: 4.0053453e-02  \n",
      "1700. Out: 4.0462643e-02  In: 4.0053360e-02  \n",
      "1800. Out: 4.0463023e-02  In: 4.0053334e-02  \n",
      "1900. Out: 4.0463328e-02  In: 4.0053334e-02  \n",
      "2000. Out: 4.0463507e-02  In: 4.0053315e-02  \n",
      "2100. Out: 4.0463578e-02  In: 4.0053319e-02  \n",
      "2200. Out: 4.0463716e-02  In: 4.0053278e-02  \n",
      "2300. Out: 4.0463794e-02  In: 4.0053271e-02  \n",
      "2400. Out: 4.0464032e-02  In: 4.0053342e-02  \n",
      "2500. Out: 4.0463939e-02  In: 4.0053289e-02  \n",
      "2600. Out: 4.0463969e-02  In: 4.0053312e-02  \n",
      "2700. Out: 4.0463962e-02  In: 4.0053301e-02  \n",
      "2800. Out: 4.0463965e-02  In: 4.0053271e-02  \n",
      "2900. Out: 4.0464003e-02  In: 4.0053278e-02  \n",
      "3000. Out: 4.0464185e-02  In: 4.0053379e-02  \n",
      "3100. Out: 4.0463999e-02  In: 4.0053267e-02  \n",
      "3200. Out: 4.0464111e-02  In: 4.0053379e-02  \n",
      "3300. Out: 4.0464077e-02  In: 4.0053301e-02  \n",
      "3400. Out: 4.0464081e-02  In: 4.0053282e-02  \n",
      "3500. Out: 4.0464062e-02  In: 4.0053301e-02  \n",
      "3600. Out: 4.0464103e-02  In: 4.0053289e-02  \n",
      "3700. Out: 4.0464029e-02  In: 4.0053263e-02  \n",
      "3800. Out: 4.0464088e-02  In: 4.0053301e-02  \n",
      "3900. Out: 4.0464025e-02  In: 4.0053271e-02  \n",
      "4000. Out: 4.0464025e-02  In: 4.0053267e-02  \n",
      "4100. Out: 4.0464036e-02  In: 4.0053271e-02  \n",
      "4200. Out: 4.0464096e-02  In: 4.0053286e-02  \n",
      "4300. Out: 4.0464051e-02  In: 4.0053282e-02  \n",
      "4400. Out: 4.0464032e-02  In: 4.0053274e-02  \n",
      "4500. Out: 4.0464062e-02  In: 4.0053267e-02  \n",
      "4600. Out: 4.0464088e-02  In: 4.0053383e-02  \n",
      "4700. Out: 4.0464029e-02  In: 4.0053267e-02  \n",
      "4800. Out: 4.0464062e-02  In: 4.0053271e-02  \n",
      "4900. Out: 4.0464103e-02  In: 4.0053319e-02  \n",
      "5000. Out: 4.0464051e-02  In: 4.0053282e-02  \n",
      "5100. Out: 4.0464073e-02  In: 4.0053274e-02  \n",
      "5200. Out: 4.0464114e-02  In: 4.0053356e-02  \n",
      "5300. Out: 4.0464118e-02  In: 4.0053301e-02  \n",
      "5400. Out: 4.0464070e-02  In: 4.0053301e-02  \n",
      "5500. Out: 4.0464073e-02  In: 4.0053286e-02  \n",
      "5600. Out: 4.0464018e-02  In: 4.0053278e-02  \n",
      "5700. Out: 4.0464066e-02  In: 4.0053267e-02  \n",
      "5800. Out: 4.0464025e-02  In: 4.0053278e-02  \n",
      "5900. Out: 4.0464059e-02  In: 4.0053271e-02  \n",
      "6000. Out: 4.0464040e-02  In: 4.0053267e-02  \n",
      "6100. Out: 4.0464029e-02  In: 4.0053267e-02  \n",
      "6200. Out: 4.0464032e-02  In: 4.0053260e-02  \n",
      "6300. Out: 4.0464088e-02  In: 4.0053327e-02  \n",
      "6400. Out: 4.0464021e-02  In: 4.0053293e-02  \n",
      "6500. Out: 4.0464025e-02  In: 4.0053278e-02  \n",
      "6600. Out: 4.0464062e-02  In: 4.0053274e-02  \n",
      "6700. Out: 4.0464073e-02  In: 4.0053297e-02  \n",
      "6800. Out: 4.0464073e-02  In: 4.0053278e-02  \n",
      "6900. Out: 4.0464025e-02  In: 4.0053267e-02  \n",
      "7000. Out: 4.0464152e-02  In: 4.0053315e-02  \n",
      "7100. Out: 4.0464062e-02  In: 4.0053278e-02  \n",
      "7200. Out: 4.0464040e-02  In: 4.0053267e-02  \n",
      "7300. Out: 4.0464047e-02  In: 4.0053282e-02  \n",
      "7400. Out: 4.0464077e-02  In: 4.0053282e-02  \n",
      "7500. Out: 4.0464044e-02  In: 4.0053278e-02  \n",
      "7600. Out: 4.0464051e-02  In: 4.0053267e-02  \n",
      "7700. Out: 4.0464073e-02  In: 4.0053289e-02  \n",
      "7800. Out: 4.0464051e-02  In: 4.0053267e-02  \n",
      "7900. Out: 4.0464066e-02  In: 4.0053271e-02  \n",
      "8000. Out: 4.0464059e-02  In: 4.0053274e-02  \n",
      "8100. Out: 4.0464137e-02  In: 4.0053304e-02  \n",
      "8200. Out: 4.0464044e-02  In: 4.0053282e-02  \n",
      "8300. Out: 4.0464025e-02  In: 4.0053267e-02  \n",
      "8400. Out: 4.0464018e-02  In: 4.0053282e-02  \n",
      "8500. Out: 4.0464047e-02  In: 4.0053308e-02  \n",
      "8600. Out: 4.0464230e-02  In: 4.0053327e-02  \n",
      "8700. Out: 4.0464044e-02  In: 4.0053271e-02  \n",
      "8800. Out: 4.0464047e-02  In: 4.0053293e-02  \n",
      "8900. Out: 4.0464029e-02  In: 4.0053315e-02  \n",
      "9000. Out: 4.0464062e-02  In: 4.0053278e-02  \n",
      "9100. Out: 4.0464051e-02  In: 4.0053267e-02  \n",
      "9200. Out: 4.0464107e-02  In: 4.0053293e-02  \n",
      "9300. Out: 4.0464085e-02  In: 4.0053282e-02  \n",
      "9400. Out: 4.0464032e-02  In: 4.0053301e-02  \n",
      "9500. Out: 4.0464040e-02  In: 4.0053267e-02  \n",
      "9600. Out: 4.0464051e-02  In: 4.0053267e-02  \n",
      "9700. Out: 4.0464111e-02  In: 4.0053271e-02  \n",
      "9800. Out: 4.0464040e-02  In: 4.0053263e-02  \n",
      "9900. Out: 4.0464044e-02  In: 4.0053297e-02  \n",
      "10000. Out: 4.0464044e-02  In: 4.0053271e-02  \n"
     ]
    }
   ],
   "source": [
    "model, optimizer = create_model(\"test_model\", load_checkpoint=False, num_layers=num_layers, seq_len=seq_len)\n",
    "loss_obj = tf.keras.losses.KLDivergence()\n",
    "\n",
    "(xt, yt) = create_dataset(N=1000) # test\n",
    "epoch = 1\n",
    "\n",
    "(x, y) = create_dataset(N=100)\n",
    "print(f\"{epoch:3}. Out: {evaluate(model, xt, yt):.7e}  In: {evaluate(model, x, y):.7e}  \")\n",
    "\n",
    "for _ in range(10_000):        \n",
    "    epoch += 1\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "            pred = model(x, training=True)        \n",
    "\n",
    "            loss = loss_obj(y, pred)\n",
    "#                 print(loss)\n",
    "    #         loss = tf.keras.losses.binary_crossentropy(y_true=y, y_pred=logits, from_logits=True)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_weights)                \n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "#     (xt, yt) = create_dataset(N=100)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"{epoch:3}. Out: {evaluate(model, xt, yt):.7e}  In: {evaluate(model, x, y):.7e}  \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
